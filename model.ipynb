{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "\n",
    "# Check if TensorFlow is using a GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"TensorFlow is running on GPU\")\n",
    "else:\n",
    "    print(\"TensorFlow is running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Load dataset\n",
    "\n",
    "data_path = \"dataset/\"\n",
    "emotions = os.listdir(data_path)\n",
    "\n",
    "# Check for '.DS_Store' and delete it\n",
    "if '.DS_Store' in emotions:\n",
    "    os.remove(os.path.join(data_path, '.DS_Store'))\n",
    "    emotions.remove('.DS_Store')\n",
    "\n",
    "print(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 48 #By default, the images in FER2013 dataset is in 48x48\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Looping through subfolders in the data path\n",
    "for emotion in emotions:\n",
    "    emotion_folder = os.path.join(data_path, emotion)\n",
    "    print(emotion_folder)\n",
    "    if not os.path.isdir(emotion_folder):\n",
    "        continue\n",
    "    for img in os.listdir(emotion_folder):\n",
    "        img_path = os.path.join(emotion_folder, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (img_size, img_size))\n",
    "            data.append(img)\n",
    "            labels.append(emotions.index(emotion))\n",
    "\n",
    "# Convert image data and labels to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Plot the distribution of the labels, bar graph\n",
    "plt.hist(labels, bins=len(emotions))\n",
    "plt.xticks(range(len(emotions)), emotions, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_images(images):\n",
    "#     processed_images = []\n",
    "#     for img in images:\n",
    "#         # Convert to color if necessary\n",
    "#         if img.shape[-1] != 3:\n",
    "#             img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "#         # Resize the image to 48x48 if necessary\n",
    "#         if img.shape[:2] != (48, 48):\n",
    "#             img = cv2.resize(img, (48, 48))\n",
    "        \n",
    "#         processed_images.append(img)\n",
    "    \n",
    "#     return np.array(processed_images)\n",
    "\n",
    "def display_samples(images, true_values, predicted_values, num_samples=9):\n",
    "    # Choose random indices\n",
    "    indices = np.random.choice(np.arange(images.shape[0]), size=num_samples, replace=False)\n",
    "\n",
    "    # Initialize subplots\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "    # For each subplot\n",
    "    for i, idx in enumerate(indices):\n",
    "        # Get the sample image and its corresponding true and predicted values\n",
    "        sample_image = images[idx]\n",
    "        true_value = true_values[idx]\n",
    "        predicted_value = predicted_values[idx]\n",
    "\n",
    "        # Display the sample image with the true and predicted valence and arousal rates\n",
    "        axs[i//3, i%3].imshow(sample_image, cmap='gray')\n",
    "        axs[i//3, i%3].set_title(f'True: {true_value[0]:.2f}, {true_value[1]:.2f}\\nPredicted: {predicted_value[0]:.2f}, {predicted_value[1]:.2f}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Load the images and their labels\n",
    "image_dir = \"./dataset/\"\n",
    "labels = []\n",
    "images = []\n",
    "\n",
    "emotion_to_valence_arousal = {\n",
    "    'happy': (0.8, 0.6),\n",
    "    'sad': (-0.8, -0.6),\n",
    "    'neutral': (0.0, 0.0),\n",
    "    'disgust': (-0.6, -0.6),\n",
    "    'surprise': (0.6, 0.8),\n",
    "    'angry': (-0.8, 0.8),\n",
    "    'fear': (0.0, 0.8)\n",
    "}\n",
    "\n",
    "for folder in os.listdir(image_dir):\n",
    "    for file in os.listdir(os.path.join(image_dir, folder)):\n",
    "        if file.endswith(\".jpg\"):\n",
    "            img = load_img(os.path.join(image_dir, folder, file), target_size=(48, 48))\n",
    "            images.append(img_to_array(img))\n",
    "            labels.append(emotion_to_valence_arousal[folder])  # Map the folder name to a valence-arousal pair\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "images = np.array(images) / 255.0  # Normalize the images\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "train_images_scaled = scaler.fit_transform(train_images.reshape(-1, train_images.shape[-1])).reshape(train_images.shape)\n",
    "test_images_scaled = scaler.transform(test_images.reshape(-1, test_images.shape[-1])).reshape(test_images.shape)\n",
    "\n",
    "# Flatten the images\n",
    "train_images_flat = train_images_scaled.reshape(-1, train_images_scaled.shape[-1])\n",
    "test_images_flat = test_images_scaled.reshape(-1, test_images_scaled.shape[-1])\n",
    "\n",
    "# Apply Polynomial Features\n",
    "poly = PolynomialFeatures(2)\n",
    "train_images_poly = poly.fit_transform(train_images_flat)\n",
    "test_images_poly = poly.transform(test_images_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of images: {len(images)}\")\n",
    "print(f\"Number of labels: {len(labels)}\")\n",
    "\n",
    "print(f\"Number of training images: {len(train_images)}\")\n",
    "print(f\"Number of training labels: {len(train_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers.legacy import Adam\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.metrics import MeanSquaredError, MeanAbsoluteError\n",
    "from keras.applications import VGG16\n",
    "from sklearn.metrics import r2_score, explained_variance_score\n",
    "from keras.regularizers import l2\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,  \n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "baseModel = VGG16(weights=\"imagenet\", include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "# Use a less aggressive regularization\n",
    "headModel = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.005))(headModel)\n",
    "headModel = BatchNormalization()(headModel)\n",
    "# Use a lower dropout rate\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "# Use a less aggressive regularization\n",
    "headModel = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.005))(headModel)\n",
    "headModel = BatchNormalization()(headModel)\n",
    "# Use a lower dropout rate\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "# Use a less aggressive regularization\n",
    "headModel = Dense(1024, activation=\"relu\", kernel_regularizer=l2(0.005))(headModel)\n",
    "headModel = BatchNormalization()(headModel)\n",
    "# Use a lower dropout rate\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"linear\")(headModel)\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "for layer in baseModel.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "for layer in baseModel.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "# Unfreeze more layers\n",
    "for layer in baseModel.layers[:-8]:\n",
    "    layer.trainable = False\n",
    "for layer in baseModel.layers[-8:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 40:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 20:\n",
    "        lr *= 1e-2\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "opt = Adam(lr=1e-3)\n",
    "model.compile(optimizer=opt, \n",
    "              loss='mean_squared_error',  \n",
    "              metrics=[MeanSquaredError(name='mse'), \n",
    "                       MeanAbsoluteError(name='mae')])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.callbacks import CSVLogger, TensorBoard, EarlyStopping, LearningRateScheduler\n",
    "from livelossplot.inputs.keras import PlotLossesCallback\n",
    "\n",
    "batch_size = 32\n",
    "train_generator = datagen.flow(train_images, train_labels, batch_size=batch_size)\n",
    "val_generator = datagen.flow(test_images, test_labels, batch_size=batch_size)\n",
    "\n",
    "# Callbacks for training\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='min', restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_loss', save_weights_only=True, mode='min', verbose=1)\n",
    "\n",
    "csv_logger = CSVLogger('training.log')\n",
    "tensorboard = TensorBoard(log_dir='./result', histogram_freq=0, write_graph=True, write_images=False)\n",
    "\n",
    "# Create a new instance of the PlotLossesKeras callback\n",
    "plot_losses = PlotLossesCallback()\n",
    "\n",
    "# Create a LearningRateScheduler callback\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Add it to your list of callbacks\n",
    "callbacks = [plot_losses, checkpoint, reduce_lr, csv_logger, tensorboard, early_stopping]\n",
    "\n",
    "try:\n",
    "    model.fit(train_generator,\n",
    "              steps_per_epoch=len(train_images) // batch_size,\n",
    "              epochs=150,\n",
    "              validation_data=val_generator,\n",
    "              validation_steps=len(test_images) // batch_size,\n",
    "              verbose=1, workers=4,\n",
    "              callbacks=callbacks)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted. Saving model...\")\n",
    "    model.save(\"model_weights.h5\")\n",
    "\n",
    "# Predict the valence-arousal coordinates for the test images\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, explained_variance_score\n",
    "\n",
    "# Additional evaluation metrics\n",
    "r2 = r2_score(test_labels, predictions)\n",
    "evs = explained_variance_score(test_labels, predictions)  # Corrected line\n",
    "\n",
    "print(f'R2 Score: {r2:.4f}')\n",
    "print(f'Explained Variance Score: {evs:.4f}')\n",
    "\n",
    "display_samples(test_images, test_labels, predictions)\n",
    "\n",
    "# Predict the valence-arousal coordinates for the test images\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "# Plot the predicted valence-arousal coordinates\n",
    "plt.scatter(predictions[:, 0], predictions[:, 1])\n",
    "plt.xlabel('Valence')\n",
    "plt.ylabel('Arousal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model architecture to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Save model's weights\n",
    "model.save_weights(\"model_weights.h5\")\n",
    "\n",
    "# Save entire model\n",
    "model.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
